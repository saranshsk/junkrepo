##########################################Installing Hive on full cluster mode##########################################

#####Download and extract Hive tar onto the installation directory using:
tar -xvzf /softwares/apache-hive-2.3.3-bin.tar.gz
sudo mv /home/hadoop/hive /usr/local/hive
sudo chmod -R 775 /usr/local/hive/
sudo chown -R hadoop /usr/local/hive/

#####On the edgenode machine install the mysql database and MySQL Java Connector using:
sudo apt-get install mysql-server
sudo apt-get install libmysql-java
When asked to enter password for root user, enter the password

#####Create soft link for connector in Hive lib directory  or copy connector jar to lib folder:
ln -s /usr/share/java/mysql-connector-java.jar /usr/local/hive/lib/mysql-connector-java.jar

#####slf4j class path contains multiple slf4j bindings in Hive and Hadoop:
In order to resolve this issue, you need to delete these jar files binding between Hadoop and Hive by running the below
rm /usr/local/hive/lib/hive-jdbc-2.0.0-standalone.jar
rm /usr/local/hive/lib/log4j-slf4j-impl-2.4.1.jar

#####Append the Hive installation directory path in PATH variable:
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64
export PATH=$PATH:$JAVA_HOME/bin
export HIVE_PREFIX=/usr/local/hive
export PATH=$PATH:$HIVE_PREFIX/bin

#####Create hive related directories inside hdfs
hadoop fs -mkdir       /tmp
hadoop fs -mkdir       /user
hadoop fs -mkdir       /user/hive
hadoop fs -mkdir       /user/hive/warehouse
hadoop fs -chmod g+w   /tmp
hadoop fs -chmod g+w   /user/hive/warehouse

#####Create the Initial database schema using the hive-schema-0.14.0.mysql.sql file ( or the file corresponding to your installed version of Hive) located in the $HIVE_PREFIX/scripts/metastore/upgrade/mysql directory:
mysql -u root -p
Enter the password for root user here
mysql> CREATE DATABASE metastore; 
mysql> USE metastore;
mysql> SOURCE /usr/local/hive/scripts/metastore/upgrade/mysql/hive-schema-2.1.1000.mysql.sql;
mysql> SOURCE /usr/local/hive/scripts/metastore/upgrade/mysql/hive-txn-schema-2.1.0.mysql.sql;
mysql> CREATE USER 'hadoop'@'%' IDENTIFIED BY 'hadoop'; 
mysql> GRANT all on *.* to 'hadoop'@localhost identified by 'hadoop';
mysql> flush privileges;

#####Connect to old hive query language prompt:
hive

#####Start the hiveserver2 services and connect using beeline:
hive --service hiveserver2 --hiveconf hive.root.logger=INFO,console
beeline -u jdbc:hive2://localhost:10000 -n hadoop
